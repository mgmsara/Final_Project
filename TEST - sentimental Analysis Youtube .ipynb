{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93fc037",
   "metadata": {},
   "source": [
    "INFO:\n",
    "\n",
    "https://www.youtube.com/watch?v=QpzMWQvxXWk&list=PL7RwtdVQXQ8o6CYe1Teo7FzkrQQoT0c9i\n",
    "    \n",
    "https://www.kaggle.com/code/robikscube/sentiment-analysis-python-youtube-tutorial/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49880f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tweepy\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931d61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('musk_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae0a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Woke v Woke https://t.co/hmhC5eelik</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@EthanBitcoin @dergigi lol</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@EddieZipperer https://t.co/92voOIH5d8</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @teslaownersSV: Tesla Semi is super quiet w...</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @SpaceX: Teams completed additional vehicle...</td>\n",
       "      <td>2022-12-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Text    Date_New\n",
       "0   0                Woke v Woke https://t.co/hmhC5eelik  2022-12-08\n",
       "1   1                         @EthanBitcoin @dergigi lol  2022-12-08\n",
       "2   2             @EddieZipperer https://t.co/92voOIH5d8  2022-12-08\n",
       "3   3  RT @teslaownersSV: Tesla Semi is super quiet w...  2022-12-08\n",
       "4   4  RT @SpaceX: Teams completed additional vehicle...  2022-12-07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a1bb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Woke v Woke https://t.co/hmhC5eelik</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@EthanBitcoin @dergigi lol</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@EddieZipperer https://t.co/92voOIH5d8</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @teslaownersSV: Tesla Semi is super quiet w...</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @SpaceX: Teams completed additional vehicle...</td>\n",
       "      <td>2022-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>908</td>\n",
       "      <td>@BillyM2k Totally agree!</td>\n",
       "      <td>2022-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>909</td>\n",
       "      <td>RT @robinw: https://t.co/05QY6u4FSD</td>\n",
       "      <td>2022-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>910</td>\n",
       "      <td>@TOIPlus Nope, I was alway ðŸ¥œ !</td>\n",
       "      <td>2022-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>911</td>\n",
       "      <td>@ZubyMusic Yeah</td>\n",
       "      <td>2022-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>@lawrencekitema @SpaceNews_Inc Congratulations!</td>\n",
       "      <td>2022-11-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                               Text    Date_New\n",
       "0      0                Woke v Woke https://t.co/hmhC5eelik  2022-12-08\n",
       "1      1                         @EthanBitcoin @dergigi lol  2022-12-08\n",
       "2      2             @EddieZipperer https://t.co/92voOIH5d8  2022-12-08\n",
       "3      3  RT @teslaownersSV: Tesla Semi is super quiet w...  2022-12-08\n",
       "4      4  RT @SpaceX: Teams completed additional vehicle...  2022-12-07\n",
       "..   ...                                                ...         ...\n",
       "908  908                           @BillyM2k Totally agree!  2022-11-09\n",
       "909  909                RT @robinw: https://t.co/05QY6u4FSD  2022-11-09\n",
       "910  910                     @TOIPlus Nope, I was alway ðŸ¥œ !  2022-11-09\n",
       "911  911                                    @ZubyMusic Yeah  2022-11-09\n",
       "912  912    @lawrencekitema @SpaceNews_Inc Congratulations!  2022-11-09\n",
       "\n",
       "[913 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename({'Unnamed: 0': 'Id'}, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93448712",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (871505139.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Basic NLTK\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Basic NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77158372",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df['Text'][50]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309821f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8995f53",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7195882",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2eec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1. VADER Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd83a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c06e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I am so happy!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('This is the worst thing ever.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['Text']\n",
    "    myid = row['Id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders = vaders.merge(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318776c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57361111",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot VADER results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=vaders, x='Score', y='compound')\n",
    "ax.set_title('Compund Score by Amazon Star Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d747466",
   "metadata": {},
   "source": [
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa960601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twint in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (2.1.20)\n",
      "Requirement already satisfied: fake-useragent in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (1.1.1)\n",
      "Requirement already satisfied: aiohttp-socks in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (0.7.1)\n",
      "Requirement already satisfied: aiodns in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (3.0.0)\n",
      "Requirement already satisfied: pysocks in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (1.7.1)\n",
      "Requirement already satisfied: geopy in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (2.3.0)\n",
      "Requirement already satisfied: elasticsearch in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (8.5.3)\n",
      "Requirement already satisfied: cchardet in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (2.1.7)\n",
      "Requirement already satisfied: pandas in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (1.4.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (4.11.1)\n",
      "Requirement already satisfied: schedule in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (1.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (3.8.1)\n",
      "Requirement already satisfied: googletransx in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from twint) (2.4.2)\n",
      "Requirement already satisfied: pycares>=4.0.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiodns->twint) (4.2.2)\n",
      "Requirement already satisfied: cffi>=1.5.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from pycares>=4.0.0->aiodns->twint) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.21)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->twint) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->twint) (4.1.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp->twint) (3.3)\n",
      "Requirement already satisfied: python-socks[asyncio]<3.0.0,>=2.0.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from aiohttp-socks->twint) (2.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->twint) (2.3.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from elasticsearch->twint) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch->twint) (1.26.9)\n",
      "Requirement already satisfied: certifi in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch->twint) (2021.10.8)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from fake-useragent->twint) (5.10.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from importlib-resources>=5.0->fake-useragent->twint) (3.7.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from geopy->twint) (2.0)\n",
      "Requirement already satisfied: requests in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from googletransx->twint) (2.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from pandas->twint) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from pandas->twint) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from pandas->twint) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->twint) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c220b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff569b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "c.Search= 'electric car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aadf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.Min_likes = 10\n",
    "c.Count = True\n",
    "c.Since = \"2020-01-01\"\n",
    "c.Store_csv = True # This is for storing file in csv format (if you want in json file it will be c.Store_json=True)\n",
    "c.Output = 'car1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f260e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Finished: Successfully collected 0 Tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!"
     ]
    }
   ],
   "source": [
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdebca81",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'EVs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEVs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EVs.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('EVs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ae63b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m11\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(11).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e40f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: click in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e335703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (4.12.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d54f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountry\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.1 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from pycountry) (61.2.0)\n",
      "Building wheels for collected packages: pycountry\n",
      "  Building wheel for pycountry (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=3061eb0cf5341c5badc841aa4dfd08096bda33edfaea7862ec4bc6185db2aebe\n",
      "  Stored in directory: /Users/saori/Library/Caches/pip/wheels/47/15/92/e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
      "Successfully built pycountry\n",
      "Installing collected packages: pycountry\n",
      "Successfully installed pycountry-22.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c5d2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 981 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=d8b0de8463b3944f5e07b2ec9df47c117351bb766edb352f4694bebd84917f68\n",
      "  Stored in directory: /Users/saori/Library/Caches/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f76beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting searchtweets\n",
      "  Downloading searchtweets-1.7.6-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from searchtweets) (2.27.1)\n",
      "Requirement already satisfied: pyyaml in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from searchtweets) (6.0)\n",
      "Collecting tweet-parser\n",
      "  Downloading tweet_parser-1.13.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests->searchtweets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests->searchtweets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests->searchtweets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saori/opt/anaconda3/lib/python3.9/site-packages (from requests->searchtweets) (2021.10.8)\n",
      "Installing collected packages: tweet-parser, searchtweets\n",
      "Successfully installed searchtweets-1.7.6 tweet-parser-1.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install searchtweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "277df9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f183ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = \"Type your consumer key here\"\n",
    "consumerSecret = \"Type your consumer secret here\"\n",
    "accessToken = \"Type your accedd token here\"\n",
    "accessTokenSecret = \"Type your access token secret here\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc206a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'vcCmOETCASdUd0CpAdCtAT1H7'\n",
    "\n",
    "api_secret = '8KEdeRxbIiQdRzC5oQFpJreC6b87I3LN2Sq6cwLXlkBB1aEGTw'\n",
    "\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAKnFRAEAAAAA0WTW5LZ0FZm0YaTCHQpjYW2BzmI%3DAis5txxF8CKfT5UfsbcG9UznM61bmjCuN6FqlZwqJIjycjw9Hl'\n",
    "\n",
    "access_token = '1410231389220376584-B2PrnZFEXKU6coWb3AEWGPODV4YJ9F'\n",
    "\n",
    "access_token_secret = 'PPwZ8sh80xzCPochgHytGCzk3USP2RQkmUeRPqq2LqiHR'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68ec94d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter keyword or hashtag to search: electric car\n",
      "Please enter how many tweets to analyze: 2000\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole) \n",
    "\n",
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze: \"))\n",
    "\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "positive  = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    \n",
    "    #print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    \n",
    "    if neg > pos:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "    \n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2dc2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number:  2000\n",
      "positive number:  677\n",
      "negative number:  603\n",
      "neutral number:  720\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "print(\"positive number: \",len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \",len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9bd59b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @WayneDupreeShow: Sorry itâ€™s -40 degrees ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Blazespage: So, most of you know we're 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @NIOAdmirer: Germany's EnBW, which invests ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @WayneDupreeShow: Sorry itâ€™s -40 degrees ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@uneed2calmdown @elonmusk @SenatorSinema oh yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>RT @RANDCorporation: China could one day use c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I need the electric dominos car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>RT @RobotAndAIWorld: Introducing 19_19, CitroÃ«...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>China could one day use cobaltâ€”a key material ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>RT @segundoatdell: An amazing fully-electric a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     RT @WayneDupreeShow: Sorry itâ€™s -40 degrees ou...\n",
       "1     RT @Blazespage: So, most of you know we're 100...\n",
       "2     RT @NIOAdmirer: Germany's EnBW, which invests ...\n",
       "3     RT @WayneDupreeShow: Sorry itâ€™s -40 degrees ou...\n",
       "4     @uneed2calmdown @elonmusk @SenatorSinema oh yo...\n",
       "...                                                 ...\n",
       "1995  RT @RANDCorporation: China could one day use c...\n",
       "1996                    I need the electric dominos car\n",
       "1997  RT @RobotAndAIWorld: Introducing 19_19, CitroÃ«...\n",
       "1998  China could one day use cobaltâ€”a key material ...\n",
       "1999  RT @segundoatdell: An amazing fully-electric a...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
